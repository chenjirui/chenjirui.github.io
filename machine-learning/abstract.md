#	机器学习算法分类
+	按学习的方式来划分

监督学习：
输入数据带有标签
监督学习建立一个学习过程，将预测结果与 “训练数据”（即输入数据）的实际结果进行比较，
不断的调整预测模型，直到模型的预测结果达到一个预期的准确率，
比如分类和回归问题等。常用算法包括决策树、贝叶斯分类、最小二乘回归、逻辑回归、支持向量机、神经网络等。

非监督学习：
输入数据没有标签
通过算法来推断数据的内在联系，比如聚类和关联规则学习等。
常用算法包括独立成分分析、K-Means 和 Apriori 算法等。

半监督学习：
输入数据部分标签，是监督学习的延伸
常用于分类和回归。
常用算法包括图论推理算法、拉普拉斯支持向量机等。

强化学习：
输入数据作为对模型的反馈，
强调如何基于环境而行动，以取得最大化的预期利益。
与监督式学习之间的区别在于，它并不需要出现正确的输入 / 输出对，也不需要精确校正次优化的行为。
强化学习更加专注于在线规划，需要在探索（在未知的领域）和遵从（现有知识）之间找到平衡。



+	回归算法
    线性回归
    逻辑回归
    多元自适应回归（MARS）
    本地散点平滑估计（LOESS）
    
+	基于实例的学习算法
    K - 邻近算法（kNN）
    学习矢量化（LVQ）
    自组织映射算法（SOM）
    局部加权学习算法（LWL）
    
+	正则化算法
    岭回归（Ridge Regression）
    LASSO（Least Absolute Shrinkage and Selection Operator）
    Elastic Net
    最小角回归（LARS）
    
+	决策树算法
    分类和回归树（CART）
    ID3 算法 (Iterative Dichotomiser 3)
    C4.5 和 C5.0
    CHAID（Chi-squared Automatic Interaction Detection(）
    随机森林（Random Forest）
    多元自适应回归样条（MARS）
    梯度推进机（Gradient Boosting Machine， GBM）
    
+	贝叶斯算法
    朴素贝叶斯
    高斯朴素贝叶斯
    多项式朴素贝叶斯
    AODE（Averaged One-Dependence Estimators）
    贝叶斯网络（Bayesian Belief Network）
    
+	基于核的算法
    支持向量机（SVM）
    径向基函数（Radial Basis Function ，RBF)
    线性判别分析（Linear Discriminate Analysis ，LDA)

+	聚类算法
    K - 均值
    K - 中位数
    EM 算法
    分层聚类
    
+	关联规则学习
    Apriori 算法
    Eclat 算法
    
+	神经网络
    感知器
    反向传播算法（BP）
    Hopfield 网络
    径向基函数网络（RBFN）
    
+	深度学习
    深度玻尔兹曼机（DBM）
    卷积神经网络（CNN）
    递归神经网络（RNN、LSTM）
    栈式自编码算法（Stacked Auto-Encoder）
    
+	降维算法
    主成分分析法（PCA）
    主成分回归（PCR）
    偏最小二乘回归（PLSR）
    萨蒙映射
    多维尺度分析法（MDS）
    投影寻踪法（PP）
    线性判别分析法（LDA）
    混合判别分析法（MDA）
    二次判别分析法（QDA）
    灵活判别分析法（Flexible Discriminant Analysis，FDA
    
+	集成算法
    Boosting
    Bagging
    AdaBoost
    堆叠泛化（混合）
    GBM 算法
    GBRT 算法
    随机森林
    
+	其他算法
    特征选择算法
    性能评估算法
    自然语言处理
    计算机视觉
    推荐系统
    强化学习
    迁移学习